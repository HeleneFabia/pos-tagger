{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef03e42-8062-475f-81ab-2da3b6e1c444",
   "metadata": {},
   "source": [
    "# Training and Evaluating a POS Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e045bb0-5606-4c4f-9aa1-454f8f9dcbe2",
   "metadata": {},
   "source": [
    "**Goal**\n",
    "- assign POS tag to each word\n",
    "    - x = first column of conll, y = second column of conll\n",
    "\n",
    "**Plan**\n",
    "- preprocess data\n",
    "    - numerical classes bsed on unique POS tags\n",
    "    - encoded strings (look at ways to do that)\n",
    "- decide on model (have to be able to explain it!)\n",
    "- train and evaluation loop\n",
    "- pick appropriate metric (F1! precision? recall?)\n",
    "- optional: create some nice plots, e.g.: confusion matrix, learning curve, precision-recall curve\n",
    "- optional: analyse dataset (distribution of POS tages, most common words per POS tag, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6919a5db-bfd1-40b7-b69b-ced434d93ddd",
   "metadata": {},
   "source": [
    "**Model**\n",
    "- decision tree: create features for each word (https://nlpforhackers.io/training-pos-tagger/)\n",
    "- LSTM/RNN with word ids based on unique words --> study how LSTM/RNN network works!\n",
    "\n",
    "if tokenization: use spcy en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "058a3065-291f-4c5d-9d92-9d4a380df53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "c6e1e430-e29a-487b-b384-d92c859dc7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "#from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "#from gensim.models.keyedvectors import load_word2vec_format\n",
    "#from gensim.models import FastText\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from utils import get_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6014b8-9803-41ad-b943-1a505a597b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043954c3-84d9-4a24-843b-08ea1c59a120",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264d47bd-8e38-4875-97c8-ba59a60510d8",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a7411008-a8d5-4b9c-8c93-42d730665053",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.txt') as f:\n",
    "    train_data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df71d5c9-0bd5-4290-890b-e89a0d1e5a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into sentences\n",
    "\n",
    "lines = list()\n",
    "lines.append(list()) \n",
    "current_idx = 0\n",
    "\n",
    "for string in train_data:\n",
    "    if string == \"\\n\":\n",
    "        lines.append(list())\n",
    "        current_idx += 1\n",
    "    else:\n",
    "        lines[current_idx].append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "44b2d526-0333-4bc3-8fd1-8fe173f84ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. number of words per sentence: 23.7\n",
      "Total number of sentences: 8937\n"
     ]
    }
   ],
   "source": [
    "words_per_line = []\n",
    "for line in lines:\n",
    "    words_per_line.append(len(line))\n",
    "    \n",
    "print(f\"Avg. number of words per sentence: {np.mean(words_per_line):.1f}\")\n",
    "print(f\"Total number of sentences: {len(lines)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "67fbff8f-205b-4308-b600-3b95b06f824a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chancellor NNP O\\n', 'of IN B-PP\\n', 'the DT B-NP\\n', 'Exchequer NNP I-NP\\n', 'Nigel NNP B-NP\\n', 'Lawson NNP I-NP\\n', \"'s POS B-NP\\n\", 'restated VBN I-NP\\n', 'commitment NN I-NP\\n', 'to TO B-PP\\n', 'a DT B-NP\\n', 'firm NN I-NP\\n', 'monetary JJ I-NP\\n', 'policy NN I-NP\\n', 'has VBZ B-VP\\n', 'helped VBN I-VP\\n', 'to TO I-VP\\n', 'prevent VB I-VP\\n', 'a DT B-NP\\n', 'freefall NN I-NP\\n', 'in IN B-PP\\n', 'sterling NN B-NP\\n', 'over IN B-PP\\n', 'the DT B-NP\\n', 'past JJ I-NP\\n', 'week NN I-NP\\n', '. . O\\n']\n"
     ]
    }
   ],
   "source": [
    "print(lines[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ca0dd69-559c-4d08-ad59-8895f06d82b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each sentence, extract each word and corresponding POS tag\n",
    "\n",
    "text = list()\n",
    "target = list()\n",
    "\n",
    "for line in lines:\n",
    "    words = list()\n",
    "    pos_tags = list()\n",
    "    for string in line:\n",
    "        word, pos, _ = string.split()\n",
    "        words.append(word)\n",
    "        pos_tags.append(pos)\n",
    "    text.append(words)\n",
    "    target.append(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e27adbe-fa21-4b86-addf-a91897cd52fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"text\": text, \"target\": target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c354ae2e-b89a-4bff-87b1-3889921d761e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Confidence, in, the, pound, is, widely, expec...</td>\n",
       "      <td>[NN, IN, DT, NN, VBZ, RB, VBN, TO, VB, DT, JJ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Chancellor, of, the, Exchequer, Nigel, Lawson...</td>\n",
       "      <td>[NNP, IN, DT, NNP, NNP, NNP, POS, VBN, NN, TO,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[But, analysts, reckon, underlying, support, f...</td>\n",
       "      <td>[CC, NNS, VBP, VBG, NN, IN, NN, VBZ, VBN, VBN,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[This, has, increased, the, risk, of, the, gov...</td>\n",
       "      <td>[DT, VBZ, VBN, DT, NN, IN, DT, NN, VBG, VBN, T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[``, The, risks, for, sterling, of, a, bad, tr...</td>\n",
       "      <td>[``, DT, NNS, IN, NN, IN, DT, JJ, NN, NN, VBP,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[``, If, there, is, another, bad, trade, numbe...</td>\n",
       "      <td>[``, IN, EX, VBZ, DT, JJ, NN, NN, ,, EX, MD, V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Forecasts, for, the, trade, figures, range, w...</td>\n",
       "      <td>[NNS, IN, DT, NN, NNS, VBP, RB, ,, CC, JJ, NNS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[The, August, deficit, and, the, #, 2.2, billi...</td>\n",
       "      <td>[DT, NNP, NN, CC, DT, #, CD, CD, NN, VBN, IN, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Sanjay, Joshi, ,, European, economist, at, Ba...</td>\n",
       "      <td>[NNP, NNP, ,, JJ, NN, IN, NNP, NNPS, CC, NNP, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[At, the, same, time, ,, he, remains, fairly, ...</td>\n",
       "      <td>[IN, DT, JJ, NN, ,, PRP, VBZ, RB, JJ, IN, DT, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  [Confidence, in, the, pound, is, widely, expec...   \n",
       "1  [Chancellor, of, the, Exchequer, Nigel, Lawson...   \n",
       "2  [But, analysts, reckon, underlying, support, f...   \n",
       "3  [This, has, increased, the, risk, of, the, gov...   \n",
       "4  [``, The, risks, for, sterling, of, a, bad, tr...   \n",
       "5  [``, If, there, is, another, bad, trade, numbe...   \n",
       "6  [Forecasts, for, the, trade, figures, range, w...   \n",
       "7  [The, August, deficit, and, the, #, 2.2, billi...   \n",
       "8  [Sanjay, Joshi, ,, European, economist, at, Ba...   \n",
       "9  [At, the, same, time, ,, he, remains, fairly, ...   \n",
       "\n",
       "                                              target  \n",
       "0  [NN, IN, DT, NN, VBZ, RB, VBN, TO, VB, DT, JJ,...  \n",
       "1  [NNP, IN, DT, NNP, NNP, NNP, POS, VBN, NN, TO,...  \n",
       "2  [CC, NNS, VBP, VBG, NN, IN, NN, VBZ, VBN, VBN,...  \n",
       "3  [DT, VBZ, VBN, DT, NN, IN, DT, NN, VBG, VBN, T...  \n",
       "4  [``, DT, NNS, IN, NN, IN, DT, JJ, NN, NN, VBP,...  \n",
       "5  [``, IN, EX, VBZ, DT, JJ, NN, NN, ,, EX, MD, V...  \n",
       "6  [NNS, IN, DT, NN, NNS, VBP, RB, ,, CC, JJ, NNS...  \n",
       "7  [DT, NNP, NN, CC, DT, #, CD, CD, NN, VBN, IN, ...  \n",
       "8  [NNP, NNP, ,, JJ, NN, IN, NNP, NNPS, CC, NNP, ...  \n",
       "9  [IN, DT, JJ, NN, ,, PRP, VBZ, RB, JJ, IN, DT, ...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f99fcd32-ad7c-4e4b-a7f5-3ecae1339cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if length of X and Y are the same for each sample\n",
    "\n",
    "for idx in range(len(df)):\n",
    "    if len(df[\"text\"].iloc[idx]) != len(df[\"target\"].iloc[idx]):\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a3179f06-3e97-491b-b168-204fe25d5a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for idx in [13, 20]: \n",
    "#    text = df[\"text\"].iloc[idx]\n",
    "#    pos = df[\"target\"].iloc[idx]\n",
    "#    for a, b in zip(text, pos):\n",
    "#        print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f27fe82-788b-4cdc-86af-ff21fdcf1845",
   "metadata": {},
   "source": [
    "### Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "13cdc8f1-5113-4c57-81c8-fed4134fa777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DT', 'RBS', 'TO', 'VBG', 'MD', 'POS', ',', 'PRP$', '#', 'SYM', 'PRP', 'UH', 'VBP', 'EX', '(', 'VBN', 'NNP', 'CC', 'WP', 'NNS', 'JJR', 'WRB', '.', 'RP', 'FW', 'WP$', 'CD', 'IN', 'NN', 'JJS', ':', '$', 'RBR', \"''\", 'RB', 'NNPS', 'WDT', ')', '``', 'VBD', 'VB', 'PDT', 'JJ', 'VBZ'}\n"
     ]
    }
   ],
   "source": [
    "# create POS encodings\n",
    "unique_pos_tags = set()\n",
    "for idx in range(len(df)):\n",
    "    for tag in df[\"target\"].iloc[idx]:\n",
    "        if tag not in unique_pos_tags:\n",
    "            unique_pos_tags.add(tag)\n",
    "\n",
    "print(unique_pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b104053a-cd8c-4e64-a097-d55372e76594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DT': 0, 'RBS': 1, 'TO': 2, 'VBG': 3, 'MD': 4, 'POS': 5, ',': 6, 'PRP$': 7, '#': 8, 'SYM': 9, 'PRP': 10, 'UH': 11, 'VBP': 12, 'EX': 13, '(': 14, 'VBN': 15, 'NNP': 16, 'CC': 17, 'WP': 18, 'NNS': 19, 'JJR': 20, 'WRB': 21, '.': 22, 'RP': 23, 'FW': 24, 'WP$': 25, 'CD': 26, 'IN': 27, 'NN': 28, 'JJS': 29, ':': 30, '$': 31, 'RBR': 32, \"''\": 33, 'RB': 34, 'NNPS': 35, 'WDT': 36, ')': 37, '``': 38, 'VBD': 39, 'VB': 40, 'PDT': 41, 'JJ': 42, 'VBZ': 43}\n"
     ]
    }
   ],
   "source": [
    "pos2value = dict()\n",
    "for idx, tag in enumerate(unique_pos_tags):\n",
    "    pos2value[tag] = idx\n",
    "\n",
    "print(pos2value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a123c38d-2ce3-4654-a143-f85e72da10ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_encoded = list()\n",
    "for idx in range(len(df)):\n",
    "    target_encoded = list()\n",
    "    for tag in df[\"target\"].iloc[idx]:\n",
    "        target_encoded.append(pos2value[tag])\n",
    "    targets_encoded.append(target_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a8f24108-6b45-46e0-953b-b05c419f2903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_encoded</th>\n",
       "      <th>target_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8680</th>\n",
       "      <td>[The, company, closed, at, $, 12, a, share, ,,...</td>\n",
       "      <td>[DT, NN, VBD, IN, $, CD, DT, NN, ,, RB, CD, NN...</td>\n",
       "      <td>[1, 38, 300, 15, 228, 4, 47, 141, 105, 5, 427,...</td>\n",
       "      <td>[0, 28, 39, 27, 31, 26, 0, 28, 6, 34, 26, 19, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634</th>\n",
       "      <td>[They, succeed, Robert, W., Kasten, and, John,...</td>\n",
       "      <td>[PRP, VBP, NNP, NNP, NNP, CC, NNP, NNP, NNP, ,...</td>\n",
       "      <td>[37, 2643, 839, 11080, 6, 527, 4721, 63, 900, ...</td>\n",
       "      <td>[10, 12, 16, 16, 16, 17, 16, 16, 16, 6, 18, 39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4341</th>\n",
       "      <td>[``, All, these, interconnected, computers, ma...</td>\n",
       "      <td>[``, DT, DT, VBN, NNS, VBP, PRP, JJ, TO, VB, I...</td>\n",
       "      <td>[74, 180, 11681, 437, 162, 13, 884, 3, 1082, 6...</td>\n",
       "      <td>[38, 0, 0, 15, 19, 12, 10, 42, 2, 40, 27, 18, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "8680  [The, company, closed, at, $, 12, a, share, ,,...   \n",
       "3634  [They, succeed, Robert, W., Kasten, and, John,...   \n",
       "4341  [``, All, these, interconnected, computers, ma...   \n",
       "\n",
       "                                                 target  \\\n",
       "8680  [DT, NN, VBD, IN, $, CD, DT, NN, ,, RB, CD, NN...   \n",
       "3634  [PRP, VBP, NNP, NNP, NNP, CC, NNP, NNP, NNP, ,...   \n",
       "4341  [``, DT, DT, VBN, NNS, VBP, PRP, JJ, TO, VB, I...   \n",
       "\n",
       "                                           text_encoded  \\\n",
       "8680  [1, 38, 300, 15, 228, 4, 47, 141, 105, 5, 427,...   \n",
       "3634  [37, 2643, 839, 11080, 6, 527, 4721, 63, 900, ...   \n",
       "4341  [74, 180, 11681, 437, 162, 13, 884, 3, 1082, 6...   \n",
       "\n",
       "                                         target_encoded  \n",
       "8680  [0, 28, 39, 27, 31, 26, 0, 28, 6, 34, 26, 19, ...  \n",
       "3634  [10, 12, 16, 16, 16, 17, 16, 16, 16, 6, 18, 39...  \n",
       "4341  [38, 0, 0, 15, 19, 12, 10, 42, 2, 40, 27, 18, ...  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"target_encoded\"] = targets_encoded\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac915a8-2a40-4ae2-849a-e175ff9837a4",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0bbcb449-8204-43cd-9435-3b8e306188db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras\n",
    "\n",
    "# tokenizer = Tokenizer()\n",
    "# tokenizer.fit_on_texts(text_combined)\n",
    "# text_encoded = tokenizer.texts_to_sequences(text)\n",
    "# df[\"text_encoded_keras\"] = text_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "cbc77d19-4fa8-4d48-bd67-a2f02fd77eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list()\n",
    "for idx in range(len(df)):\n",
    "    text.append([word.lower() for word in df[\"text\"].iloc[idx]])\n",
    "text_combined = [word for sentence in text for word in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "74e91a1a-a2db-4460-b682-c2ef529ac2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_lower\"] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "466faa6b-b93c-4bfd-bba8-e2ff1a16b727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17258\n"
     ]
    }
   ],
   "source": [
    "# create vocabulary based on unique words and IDs\n",
    "\n",
    "unique_words = set()\n",
    "for idx in range(len(df)):\n",
    "    for word in df[\"text\"].iloc[idx]:\n",
    "        if word.lower() not in unique_words:\n",
    "            unique_words.add(word.lower())\n",
    "\n",
    "print(len(unique_tokens))\n",
    "\n",
    "word2value = dict()\n",
    "for idx, word in enumerate(unique_words):\n",
    "    word2value[word] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6f48c846-9923-4706-8e30-5c790f064b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_encoded = list()\n",
    "for idx in range(len(df)):\n",
    "    text_encoded = list()\n",
    "    for word in df[\"text\"].iloc[idx]:\n",
    "        text_encoded.append(word2value[word.lower()])\n",
    "    texts_encoded.append(text_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3139ebdb-44a2-464b-ac8d-772a232c8c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"text_encoded\"] = texts_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "65c20b08-0a0f-4e86-8317-ba8db3d8a964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median sentence length 23.0\n",
      "Max sentence length 78\n"
     ]
    }
   ],
   "source": [
    "sentence_lengths = [len(df[\"text\"].iloc[idx]) for idx in range(len(df))]\n",
    "max_seq_length = max(sentence_lengths)\n",
    "print(\"Median sentence length\", np.median(sentence_lengths))\n",
    "print(\"Max sentence length\", max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e4b13cb9-6536-4845-8ae6-980093fb753b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_padded = pad_sequences(df[\"text_encoded\"], maxlen=max_seq_length, padding='post')\n",
    "texts_padded = [text.tolist() for text in texts_padded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1d21b44e-6203-446b-80ff-dc34e830c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_padded\"] = texts_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9e3208f3-9fd2-4288-97ad-cbbf994fdca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_encoded</th>\n",
       "      <th>target_encoded</th>\n",
       "      <th>text_padded</th>\n",
       "      <th>text_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Confidence, in, the, pound, is, widely, expec...</td>\n",
       "      <td>[NN, IN, DT, NN, VBZ, RB, VBN, TO, VB, DT, JJ,...</td>\n",
       "      <td>[7194, 2731, 15113, 10265, 2980, 15351, 8589, ...</td>\n",
       "      <td>[28, 27, 0, 28, 43, 34, 15, 2, 40, 0, 42, 28, ...</td>\n",
       "      <td>[7194, 2731, 15113, 10265, 2980, 15351, 8589, ...</td>\n",
       "      <td>[confidence, in, the, pound, is, widely, expec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Chancellor, of, the, Exchequer, Nigel, Lawson...</td>\n",
       "      <td>[NNP, IN, DT, NNP, NNP, NNP, POS, VBN, NN, TO,...</td>\n",
       "      <td>[2105, 11904, 15113, 211, 9094, 12921, 12443, ...</td>\n",
       "      <td>[16, 27, 0, 16, 16, 16, 5, 15, 28, 2, 0, 28, 4...</td>\n",
       "      <td>[2105, 11904, 15113, 211, 9094, 12921, 12443, ...</td>\n",
       "      <td>[chancellor, of, the, exchequer, nigel, lawson...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[But, analysts, reckon, underlying, support, f...</td>\n",
       "      <td>[CC, NNS, VBP, VBG, NN, IN, NN, VBZ, VBN, VBN,...</td>\n",
       "      <td>[3473, 9855, 6566, 14313, 14610, 16233, 995, 1...</td>\n",
       "      <td>[17, 19, 12, 3, 28, 27, 28, 43, 15, 15, 27, 0,...</td>\n",
       "      <td>[3473, 9855, 6566, 14313, 14610, 16233, 995, 1...</td>\n",
       "      <td>[but, analysts, reckon, underlying, support, f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  [Confidence, in, the, pound, is, widely, expec...   \n",
       "1  [Chancellor, of, the, Exchequer, Nigel, Lawson...   \n",
       "2  [But, analysts, reckon, underlying, support, f...   \n",
       "\n",
       "                                              target  \\\n",
       "0  [NN, IN, DT, NN, VBZ, RB, VBN, TO, VB, DT, JJ,...   \n",
       "1  [NNP, IN, DT, NNP, NNP, NNP, POS, VBN, NN, TO,...   \n",
       "2  [CC, NNS, VBP, VBG, NN, IN, NN, VBZ, VBN, VBN,...   \n",
       "\n",
       "                                        text_encoded  \\\n",
       "0  [7194, 2731, 15113, 10265, 2980, 15351, 8589, ...   \n",
       "1  [2105, 11904, 15113, 211, 9094, 12921, 12443, ...   \n",
       "2  [3473, 9855, 6566, 14313, 14610, 16233, 995, 1...   \n",
       "\n",
       "                                      target_encoded  \\\n",
       "0  [28, 27, 0, 28, 43, 34, 15, 2, 40, 0, 42, 28, ...   \n",
       "1  [16, 27, 0, 16, 16, 16, 5, 15, 28, 2, 0, 28, 4...   \n",
       "2  [17, 19, 12, 3, 28, 27, 28, 43, 15, 15, 27, 0,...   \n",
       "\n",
       "                                         text_padded  \\\n",
       "0  [7194, 2731, 15113, 10265, 2980, 15351, 8589, ...   \n",
       "1  [2105, 11904, 15113, 211, 9094, 12921, 12443, ...   \n",
       "2  [3473, 9855, 6566, 14313, 14610, 16233, 995, 1...   \n",
       "\n",
       "                                          text_lower  \n",
       "0  [confidence, in, the, pound, is, widely, expec...  \n",
       "1  [chancellor, of, the, exchequer, nigel, lawson...  \n",
       "2  [but, analysts, reckon, underlying, support, f...  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5640e364-2b0c-4e69-8665-4eb3ba719c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = load_word2vec_format(\"/home/hkortschak/Repositories/commonlit_kaggle/xund/GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3a6e5a2c-ed30-422f-9086-134fd851cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 300\n",
    "vocabulary_size = len(word2value) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e62575f3-df13-4ee3-be94-4de8955f55e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4808\n"
     ]
    }
   ],
   "source": [
    "embedding_weights = np.zeros((vocabulary_size, embedding_size))\n",
    "count = 0\n",
    "for word, idx in word2value.items():\n",
    "    try: \n",
    "        embedding_weights[idx] = word2vec[word]\n",
    "    except KeyError:\n",
    "        count += 1\n",
    "        # print(word)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8b7588e3-1bca-4689-8ef2-f94e6c991ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(sentences=df[\"text_lower\"], vector_size=100, window=5, min_count=1, workers=4)\n",
    "word_vectors = word2vec_model.wv\n",
    "# word_vectors.save(\"word2vec.wordvectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a8b9b4c3-0fb8-402f-904e-fdd13931f222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('peters', 0.9969028830528259), ('she', 0.9968954920768738), ('suit', 0.9968575835227966), ('himself', 0.9968065023422241), ('bush', 0.9967989921569824), ('decision', 0.9967637658119202), ('saw', 0.9967111349105835), ('great', 0.9965247511863708), ('deloitte', 0.9962803721427917), ('whole', 0.9959662556648254)]\n"
     ]
    }
   ],
   "source": [
    "vector = word2vec_model.wv['man']  # get numpy vector of a word\n",
    "sims = word2vec_model.wv.most_similar('man', topn=10)  # get other similar words\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "a47fd631-9420-4acf-b53c-c0813b9f70d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load(\"word2vec.wordvectors\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "802fcc7e-7cdb-4f3c-8753-2018d8152a4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key '17258' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_65256/2355246713.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Repositories/commonlit_kaggle/nlp-env/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \"\"\"\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/commonlit_kaggle/nlp-env/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \"\"\"\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/commonlit_kaggle/nlp-env/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key '17258' not present\""
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afd19fbf-550e-451a-bac2-97c7556c91e8",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "fa0da986-b817-46fd-889d-47b4aac53430",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers, word_vectors):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(num_embeddings=len(word_vectors), embedding_dim=100, padding_idx=0)\n",
    "        self.embedding = nn.Embedding.from_pretrained(word_vectors)\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers)   \n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        output, hidden = self.rnn(x)\n",
    "        # getting output from the hidden state\n",
    "        output = output.view(-1, self.hidden_dim)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a4229a-a60c-45b5-935c-fa7beac26ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
